{"cells":[{"cell_type":"markdown","metadata":{"id":"5bFzgoXQrlql"},"source":["# Transformer麻雀AI 開発ワークフロー（ハイブリッド・安定版）\n","\n","**【目的】**\n","Colabのディスク容量とGoogle DriveのAPI制限の両方を考慮し、ローカルディスクとDriveを併用するハイブリッド方式で、大容量データ処理を安定して実行する。"]},{"cell_type":"markdown","metadata":{"id":"TVxNcKlmrlqp"},"source":["## STEP 1: 環境設定\n","\n","**最初に一度だけ実行してください。**\n","ライブラリをインストールし、Google Driveをマウントします。\n","`force_remount=True` オプションで、接続が不安定になった際に確実に再接続します。"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"j9PfyuyCrlqq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759305971172,"user_tz":-540,"elapsed":10779,"user":{"displayName":"SEnA -","userId":"07897138932926808776"}},"outputId":"a8b67cbc-a7ac-465f-debe-b4f1e5402aa3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: mahjong in /usr/local/lib/python3.12/dist-packages (1.3.0)\n","Mounted at /content/drive\n","/content/drive/MyDrive/いろいろ/麻雀AI/googlecolab/senasJanAI\n"]}],"source":["!pip install mahjong\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# Google Drive上のプロジェクトルートディレクトリを指定\n","GDRIVE_PROJECT_ROOT = \"/content/drive/MyDrive/いろいろ/麻雀AI/googlecolab/senasJanAI\"\n","%cd {GDRIVE_PROJECT_ROOT}"]},{"cell_type":"markdown","metadata":{"id":"ugT2i7otrlqr"},"source":["## STEP 2: データ準備（Colabローカルに展開）\n","\n","**最初に一度だけ実行してください。**\n","Driveにある `data.zip` を、Colabの**高速なローカルディスク上**に展開します。これによりDriveのAPIエラーを回避します。"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ziptest","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759306014179,"user_tz":-540,"elapsed":143,"user":{"displayName":"SEnA -","userId":"07897138932926808776"}},"outputId":"ee9e2ad6-d4a2-47f1-e446-35cd85507242"},"outputs":[{"output_type":"stream","name":"stdout","text":["Unzipped data directory already exists on local storage. Skipping unzip.\n","\n","--- Sample of extracted files on local storage: ---\n","total 3292\n","drwxr-xr-x 2 root root 3371008 Oct  1 07:52 data\n"]}],"source":["import os\n","import zipfile\n","\n","ZIP_FILE_PATH_ON_DRIVE = os.path.join(GDRIVE_PROJECT_ROOT, 'data.zip')\n","# 【変更点】展開先をColabのローカルディスクに変更\n","EXTRACT_DIR_LOCAL = '/content/data_unzipped'\n","\n","if not os.path.exists(EXTRACT_DIR_LOCAL) or not os.listdir(EXTRACT_DIR_LOCAL):\n","    print(f\"Unzipping data files to Colab's local storage...\")\n","    os.makedirs(EXTRACT_DIR_LOCAL, exist_ok=True)\n","    with zipfile.ZipFile(ZIP_FILE_PATH_ON_DRIVE, 'r') as zip_ref:\n","        zip_ref.extractall(EXTRACT_DIR_LOCAL)\n","    print(\"Unzip complete!\")\n","else:\n","    print(\"Unzipped data directory already exists on local storage. Skipping unzip.\")\n","\n","print(\"\\n--- Sample of extracted files on local storage: ---\")\n","!ls -l {EXTRACT_DIR_LOCAL} | head -n 6"]},{"cell_type":"markdown","metadata":{"id":"jCBcWAgsrlqt"},"source":["## STEP 3: データセット生成（ローカル → Driveへ保存）\n","\n","**このセルを繰り返し実行してください。**\n","ローカルの牌譜ファイルを解析し、中間データ（チャンク）を**Google Drive上**に直接保存します。中断しても、これまでの成果はDriveに保存されているので安全です。"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"mK4ttzWCrlqt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759305358730,"user_tz":-540,"elapsed":8582,"user":{"displayName":"SEnA -","userId":"07897138932926808776"}},"outputId":"de072e47-3391-4ded-fd91-f1c21df96b1b"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/いろいろ/麻雀AI/googlecolab/senasJanAI\n","Starting data generation (Local Read -> Drive Write)...\n","2025-10-01 07:55:53.189316: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1759305353.206992    2709 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1759305353.211818    2709 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","W0000 00:00:1759305353.226294    2709 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1759305353.226349    2709 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1759305353.226353    2709 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1759305353.226356    2709 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","2025-10-01 07:55:53.230574: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","--- All files have been processed. You can now proceed to the 'Sync to Drive' step in your notebook. ---\n","\n","Total execution time for this run: 0.03 seconds.\n"]}],"source":["import os\n","\n","# 【重要】スクリプト実行前に必ずプロジェクトルートに移動する\n","%cd {GDRIVE_PROJECT_ROOT}\n","\n","# generate_data.pyをハイブリッド用に修正します\n","with open('src/transformer/generate_data.py', 'r') as f:\n","    code = f.read()\n","\n","# 【変更点】\n","# 入力(DATA_DIR)はColabローカル、出力(PROCESSED_DIR)はGoogle Driveを指すように書き換える\n","code = code.replace(\"DATA_DIR = '/content/data'\", f\"DATA_DIR = '/content/data_unzipped'\")\n","code = code.replace(\"PROCESSED_DIR = '/content/processed_data'\", f\"PROCESSED_DIR = '{os.path.join(GDRIVE_PROJECT_ROOT, 'processed_data')}'\")\n","\n","with open('src/transformer/generate_data_hybrid.py', 'w') as f:\n","    f.write(code)\n","\n","print(\"Starting data generation (Local Read -> Drive Write)...\")\n","!python -m src.transformer.generate_data_hybrid"]},{"cell_type":"markdown","metadata":{"id":"merge_cell_markdown"},"source":["## STEP 4: チャンク結合 ＆ 最終データセット作成（Drive上で完結）\n","\n","**STEP 3で「All files have been processed」と表示されたら、このセルを一度だけ実行してください。**\n","Drive上に保存された中間ファイルを結合し、最終的なデータセットをDrive上に作成します。"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"merge_cell_code","colab":{"base_uri":"https://localhost:8080/","height":397},"executionInfo":{"status":"error","timestamp":1759306153789,"user_tz":-540,"elapsed":116891,"user":{"displayName":"SEnA -","userId":"07897138932926808776"}},"outputId":"5dcb6a00-2083-4fed-aa71-b1b1ab2dadb9"},"outputs":[{"output_type":"stream","name":"stdout","text":["--- Starting Final Merging Process (on Google Drive) ---\n","/content/drive/MyDrive/いろいろ/麻雀AI/googlecolab/senasJanAI\n","Found 453 chunks on Drive. Calculating total size...\n"]},{"output_type":"error","ename":"OSError","evalue":"[Errno 107] Transport endpoint is not connected","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3181259809.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Found {len(chunk_files)} chunks on Drive. Calculating total size...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Total samples to merge: {total_samples}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-3181259809.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Found {len(chunk_files)} chunks on Drive. Calculating total size...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Total samples to merge: {total_samples}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: [Errno 107] Transport endpoint is not connected"]}],"source":["import glob, pickle, numpy as np, os, tensorflow as tf\n","from src.transformer.vectorizer import MAX_CONTEXT_LENGTH, MAX_CHOICES\n","\n","# 全てのパスをGoogle Drive上のパスに設定\n","GDRIVE_PROCESSED_DIR = os.path.join(GDRIVE_PROJECT_ROOT, 'processed_data')\n","CHUNK_DIR_GDRIVE = os.path.join(GDRIVE_PROCESSED_DIR, 'chunks')\n","FINAL_DATASET_PATH_GDRIVE = os.path.join(GDRIVE_PROCESSED_DIR, 'training_dataset_transformer.pkl')\n","\n","print(\"--- Starting Final Merging Process (on Google Drive) ---\")\n","%cd {GDRIVE_PROJECT_ROOT}\n","chunk_files = sorted(glob.glob(os.path.join(CHUNK_DIR_GDRIVE, \"*.pkl\")))\n","\n","if not chunk_files:\n","    print(\"Error: No chunk files found on Drive to merge. Please run STEP 3 first.\")\n","else:\n","    print(f\"Found {len(chunk_files)} chunks on Drive. Calculating total size...\")\n","    total_samples = sum(len(pickle.load(open(f, 'rb'))[2]) for f in chunk_files)\n","    print(f\"Total samples to merge: {total_samples}\")\n","\n","    # メモリを節約するため、巨大な配列は直接作成せず、チャンクごとに追加していく\n","    contexts_final, choices_final, labels_final = [], [], []\n","\n","    progbar = tf.keras.utils.Progbar(len(chunk_files), unit_name=\"chunk\")\n","    for i, chunk_file in enumerate(chunk_files):\n","        with open(chunk_file, 'rb') as f:\n","            contexts, choices, labels = pickle.load(f)\n","        contexts_final.append(contexts)\n","        choices_final.append(choices)\n","        labels_final.append(labels)\n","        progbar.update(i + 1)\n","\n","    print(\"\\nConcatenating all chunks...\")\n","    contexts_final = np.concatenate(contexts_final, axis=0)\n","    choices_final = np.concatenate(choices_final, axis=0)\n","    labels_final = np.concatenate(labels_final, axis=0)\n","\n","    print(\"\\nGenerating final masks...\")\n","    non_zero_counts = np.count_nonzero(np.sum(choices_final, axis=2), axis=1)\n","    masks = np.zeros_like(choices_final[:, :, 0], dtype='float32')\n","    for i, count in enumerate(non_zero_counts): masks[i, :count] = 1.0\n","    final_dataset = (contexts_final, choices_final, labels_final, masks)\n","\n","    print(f\"Saving final dataset to Google Drive: '{FINAL_DATASET_PATH_GDRIVE}'...\")\n","    with open(FINAL_DATASET_PATH_GDRIVE, 'wb') as f:\n","        pickle.dump(final_dataset, f, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","    print(\"\\n--- Merging Complete! ---\")\n","\n","    print(\"Cleaning up temporary chunk files from Google Drive...\")\n","    !rm -rf \"{CHUNK_DIR_GDRIVE}\"\n","    print(\"Done.\")"]},{"cell_type":"markdown","metadata":{"id":"6t2-RZcLrlqt"},"source":["## STEP 5: AIモデルの学習\n","\n","**STEP 4が完了したら、このセルを実行してください。**\n","Drive上の最終データセットを使ってTransformerモデルの学習を開始します。学習が終わると、完成したモデルがDriveに保存されます。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cGpX1gsRrlqu"},"outputs":[],"source":["import os\n","\n","# 【重要】スクリプト実行前に必ずプロジェクトルートに移動する\n","%cd {GDRIVE_PROJECT_ROOT}\n","\n","# train_transformer.pyをDrive上で動作するように修正します\n","with open('src/transformer/train_transformer.py', 'r') as f:\n","    code = f.read()\n","\n","# パス設定をGoogle Drive上のパスに書き換える\n","code = code.replace(\"PROCESSED_DATA_PATH = '/content/processed_data/training_dataset_transformer.pkl'\", f\"PROCESSED_DATA_PATH = '{os.path.join(GDRIVE_PROJECT_ROOT, 'processed_data', 'training_dataset_transformer.pkl')}'\")\n","code = code.replace(\"MODEL_PATH = '/content/models/senas_jan_ai_transformer_v1.keras'\", f\"MODEL_PATH = '{os.path.join(GDRIVE_PROJECT_ROOT, 'models', 'senas_jan_ai_transformer_v1.keras')}'\")\n","code = code.replace(\"os.makedirs('/content/models', exist_ok=True)\", f\"os.makedirs('{os.path.join(GDRIVE_PROJECT_ROOT, 'models')}', exist_ok=True)\")\n","\n","with open('src/transformer/train_transformer_hybrid.py', 'w') as f:\n","    f.write(code)\n","\n","print(\"--- Starting Training ---\")\n","!python -m src.transformer.train_transformer_hybrid"]},{"cell_type":"markdown","metadata":{"id":"TUtqnx_Wrlqu"},"source":["## STEP 6: 学習済みAIによる予測\n","\n","**学習が完了したら、このセルを実行してください。**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w_49-A_Frlqu"},"outputs":[],"source":["import os\n","\n","# 【重要】スクリプト実行前に必ずプロジェクトルートに移動する\n","%cd {GDRIVE_PROJECT_ROOT}\n","\n","# predict_transformer.pyをDrive上で動作するように修正します\n","with open('src/transformer/predict_transformer.py', 'r') as f:\n","    code = f.read()\n","\n","# パス設定をGoogle Drive上のパスに書き換える\n","code = code.replace(\"MODEL_PATH = '/content/models/senas_jan_ai_transformer_v1.keras'\", f\"MODEL_PATH = '{os.path.join(GDRIVE_PROJECT_ROOT, 'models', 'senas_jan_ai_transformer_v1.keras')}'\")\n","\n","with open('src/transformer/predict_transformer_hybrid.py', 'w') as f:\n","    f.write(code)\n","\n","!python -m src.transformer.predict_transformer_hybrid"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}