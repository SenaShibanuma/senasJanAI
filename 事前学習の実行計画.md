# **事前学習の実行計画（完全版）**

現在の実行環境（TensorFlow 2.10.0）で読み込み可能な、事前学習済みモデル tenho\_model.keras を新規に作成するための、詳細な実行計画です。

## **1\. 目的**

* **互換性のあるモデルの作成**: tensorflow-cpu==2.10.0 を含む、現在のPython環境で正常に読み込めるモデルファイルを作成する。  
* **強力な初期モデルの獲得**: 強化学習を開始する前に、人間のプレイヤーの打牌選択を模倣する、ある程度賢いモデルを準備する。

## **2\. 必要なもの**

1. **実行環境**:  
   * 現在 requirements.txt に基づいて構築したPython仮想環境。  
2. **モデルアーキテクチャ**:  
   * src/agent/model.py の build\_masked\_transformer 関数によって生成されるモデル。  
3. **教師データ（牌譜）**:  
   * \*\*天鳳（てんほう）\*\*形式の牌譜データ（.mjlog ファイル）。  
   * モデルの性能向上のため、少なくとも数千〜数万局分のデータが推奨されます。

## **2.5. モデルの入出力仕様（最重要）**

事前学習で作成するデータセットは、以下のモデル仕様と完全に一致している必要があります。各ベクトルの詳細な内容は **付録A** および **付録B** を参照してください。

### **入力 (Inputs)**

1. **context\_input (状況ベクトル)**: (バッチサイズ, 150, 100\)  
2. **choices\_input (選択肢ベクトル)**: (バッチサイズ, 50, 100\)  
3. **mask\_input (選択肢マスク)**: (バッチサイズ, 50\)

### **出力 (Output) と 教師ラベル (Label)**

1. **モデルの出力**: (バッチサイズ, 50\)  
2. **教師ラベル (正解データ)**: (バッチサイズ, 50\) の **one-hotベクトル**。

## **3\. 事前学習の実行ステップ**

### **Step 1: 牌譜データの準備**

1. **データ収集**: 天鳳などのサイトから、大量の牌譜データ（.mjlog形式）をダウンロードし、プロジェクト内の data/raw\_logs/ のような専用ディレクトリに保存します。  
2. **データ分割**: 収集した牌譜ファイルを、**訓練用(80%)**、**検証用(10%)**、\*\*テスト用(10%)\*\*の3つのグループにランダムに分割します。ファイル名のリストを作成して管理するのが良いでしょう。

### **Step 2: データの前処理 ( preprocess.py の作成)**

1. **目的**: Step 1で準備した牌譜データを、モデルが学習できる形式（NumPy配列の辞書）に変換します。  
2. **スクリプト作成**: preprocess.py という新しいPythonスクリプトをプロジェクトのルートに作成します。  
3. **実装内容**:  
   * 牌譜ファイル（.mjlog）を読み込み、XML形式として解析するパーサーを実装します。  
   * 各局、各プレイヤーの各手番（ツモ→打牌）のループ処理を実装します。  
   * 各手番において、「その時点でのゲーム状況（コンテキスト）」、「取りうる選択肢（打牌候補）」、そして「実際にプレイヤーが選択した打牌（正解ラベル）」を抽出します。  
   * 抽出した情報を、**付録A, B**で定義されたベクトル仕様に基づき、context\_input, choices\_input, mask\_input, labels の4つのNumPy配列に変換します。  
   * 変換したデータをまとめて、np.savez\_compressed() を使い、data/processed/train.npz, data/processed/validation.npz, data/processed/test.npz のように、分割したグループごとにファイルとして保存します。

### **Step 3: モデルの学習 ( pretrain.py の作成)**

1. **目的**: 前処理済みのデータセットを使って、モデルに人間の打牌選択を学習させます。  
2. **スクリプト作成**: pretrain.py という新しいPythonスクリプトをプロジェクトのルートに作成します。  
3. **実装内容**:  
   * data/processed/ から訓練用と検証用のデータセット（.npzファイル）を読み込みます。  
   * src.agent.model.build\_masked\_transformer を呼び出し、空のモデルを生成します。  
   * model.compile() を使ってモデルをコンパイルします。設定は以下のようにします。  
     * **optimizer**: tf.keras.optimizers.Adam(learning\_rate=1e-4)  
     * **loss**: tf.keras.losses.CategoricalCrossentropy(from\_logits=True) （モデルの出力がsoftmaxを通る前の生の値であるため）  
     * **metrics**: \['accuracy'\]  
   * 学習の進捗を監視し、最適なモデルを保存するためのコールバックを設定します。  
     * **ModelCheckpoint**: 検証用データの損失(val\_loss)が最も低くなった時点のモデルの重みを自動的に保存します。  
     * **TensorBoard**: 学習曲線などを可視化するためのログを出力します。  
     * **EarlyStopping**: 検証用データの損失が一定エポック数改善しなかった場合に、学習を早期終了させて過学習を防ぎます。  
   * model.fit() を使って学習を開始します。  
     * 入力としてcontext, choices, maskのNumPy配列を渡します。  
     * 教師ラベルとしてlabelsを渡します。  
     * validation\_data引数に検証用データセットを指定します。  
     * callbacks引数に上記で設定したコールバックを指定します。  
   * 学習が完了したら、最終的なモデルを model.save('models/tenho\_model.keras') で保存します。

## **付録A: ベクトル仕様の詳細**

### **牌IDの定義**

| 範囲 | 牌種 | 詳細 |
| :---- | :---- | :---- |
| 0-8 | マンズ (m) | 1m, 2m, ..., 9m |
| 9-17 | ピンズ (p) | 1p, 2p, ..., 9p |
| 18-26 | ソーズ (s) | 1s, 2s, ..., 9s |
| 27-33 | 字牌 (z) | 東, 南, 西, 北, 白, 発, 中 (Ton, Nan, Sha, Pei, Haku, Hatsu, Chun) |

### **1\. イベントベクトル (Event Vector) \- 100次元**

| インデックス範囲 | 内容 | 次元数 |
| :---- | :---- | :---- |
| \[0:5\] | **イベント種別** (one-hot) | 5 |
| \[5:9\] | **プレイヤー** (one-hot) | 4 |
| \[9:43\] | **関連牌** (one-hot) | 34 |
| \[43:77\] | **ドラ表示牌** (multi-hot) | 34 |
| \[77:81\] | **各プレイヤーの点数** (float) | 4 |
| \[81:85\] | **リーチ状態** (binary) | 4 |
| \[85\] | **巡目** (float) | 1 |
| \[86\] | **局** (float) | 1 |
| \[87\] | **本場** (float) | 1 |
| \[88\] | **供託リーチ棒** (float) | 1 |
| \[89:93\] | **プレイヤーの自風** (one-hot) | 4 |
| \[93\] | **場風** (int) | 1 |
| \[94:100\] | **予約** | 6 |

### **2\. 選択肢ベクトル (Choice Vector) \- 100次元**

| インデックス範囲 | 内容 | 次元数 |
| :---- | :---- | :---- |
| \[0:34\] | **捨てる牌** (one-hot) | 34 |
| \[34\] | **赤ドラか** (binary) | 1 |
| \[35\] | **ドラか** (binary) | 1 |
| \[36:45\] | **打牌後のシャンテン数** (one-hot) | 9 |
| \[45:79\] | **打牌後の待ち** (multi-hot) | 34 |
| \[79\] | **安牌度** (float) | 1 |
| \[80:100\] | **予約** | 20 |

## **付録B: ベクトル化の具体例**

**状況**: プレイヤー0（東家）の5巡目の手番。手牌は \[1m, 2m, 3m, 中, 中\] で、4m をツモってきた。人間のプレイヤーは 中 を捨てた。

### **1\. choices\_input と mask\_input の生成**

* **選択肢**: 手牌の6枚 \[1m, 2m, 3m, 4m, 中, 中\] が打牌候補となる。  
* choices\_input (形状: (1, 50, 100)):  
  * 最初の6個のベクトルが、それぞれの打牌選択に対応する情報で埋められる。  
    * choices\[0, 0, :\]: 1m を捨てた場合のベクトル (\[0\]が1, 他は0...)  
    * choices\[0, 1, :\]: 2m を捨てた場合のベクトル (\[1\]が1, 他は0...)  
    * ...  
    * choices\[0, 5, :\]: 2枚目の中を捨てた場合のベクトル (\[33\]が1, 他は0...)  
  * 残りの44個のベクトルはすべて0で埋められる（パディング）。  
* mask\_input (形状: (1, 50)):  
  * \[1, 1, 1, 1, 1, 1, 0, 0, ..., 0\] となる。最初の6つが有効な選択肢。

### **2\. labels の生成**

* **正解**: 6つの選択肢のうち、6番目の「中を捨てる」が正解。  
* labels (形状: (1, 50)):  
  * \[0, 0, 0, 0, 0, 1, 0, 0, ..., 0\] となるone-hotベクトル。

### **3\. context\_input の生成**

* **コンテキスト**: これまでのゲームの進行（局開始、各プレイヤーのツモと打牌など）が、最大150個のイベントベクトルとして記録される。  
* context\_input (形状: (1, 150, 100)):  
  * context\[0, 0, :\]: 「局開始」イベントのベクトル。  
  * context\[0, 1, :\]: プレイヤー0の1巡目の「ツモ」イベントのベクトル。  
  * context\[0, 2, :\]: プレイヤー0の1巡目の「打牌」イベントのベクトル。  
  * ...  
  * context\[0, N, :\]: この手番の直前の「ツモ(4m)」イベントのベクトル。  
  * 残りのベクトルはすべて0で埋められる（パディング）。